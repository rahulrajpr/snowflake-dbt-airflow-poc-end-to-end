services:
  # =================================================================
  # DATABASES
  # =================================================================

  # PostgreSQL Internal - For Airflow & Superset metadata
  postgres_internal:
    image: postgres:17.7-alpine
    container_name: postgres-internal-container
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_INTERNAL_USER}
      POSTGRES_PASSWORD: ${POSTGRES_INTERNAL_PASSWORD}
      POSTGRES_DB: ${POSTGRES_INTERNAL_DB}
    volumes:
      - ${POSTGRES_INTERNAL_DATA_PATH}:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    ports:
      - "5433:5432"
    networks:
      - shared-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_INTERNAL_USER} -d ${POSTGRES_INTERNAL_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5

  # PostgreSQL - For Business Database Operations
  postgres:
    image: postgres:17.7-alpine
    container_name: postgres-business-container
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ${POSTGRES_DATA_PATH}:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - shared-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5

  # PostgreSQL - For Airbyte Metadata
  airbyte-postgres:
    image: postgres:13
    container_name: airbyte-postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_AIRBYTE_USER}
      POSTGRES_PASSWORD: ${POSTGRES_AIRBYTE_PASSWORD}
      POSTGRES_DB: ${POSTGRES_AIRBYTE_DB}
    volumes:
      - ${AIRBYTE_DB_PATH}:/var/lib/postgresql/data
    ports:
      - "5434:5432"
    networks:
      - shared-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_AIRBYTE_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for Superset caching
  redis:
    image: redis:7.4-alpine
    container_name: redis-container
    restart: always
    ports:
      - "6379:6379"
    networks:
      - shared-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # =================================================================
  # AIRFLOW
  # =================================================================

  # Airflow Database Initialization (runs once)
  airflow-init:
    image: apache/airflow:2.8.1
    container_name: airflow-init-container
    depends_on:
      postgres_internal:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_INTERNAL_USER}:${POSTGRES_INTERNAL_PASSWORD}@postgres_internal/${POSTGRES_INTERNAL_DB}
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username ${AIRFLOW_ADMIN_USERNAME} --password ${AIRFLOW_ADMIN_PASSWORD} --firstname Admin --lastname User --role Admin --email admin@example.com
      "
    networks:
      - shared-network
    volumes:
      - ${AIRFLOW_DATA_PATH}:/opt/airflow

  # Apache Airflow Webserver
  airflow:
    image: apache/airflow:2.8.1
    container_name: apache-airflow-container
    restart: always
    depends_on:
      postgres_internal:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_INTERNAL_USER}:${POSTGRES_INTERNAL_PASSWORD}@postgres_internal/${POSTGRES_INTERNAL_DB}
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
    volumes:
      - ${AIRFLOW_DATA_PATH}:/opt/airflow
      - ${AIRFLOW_DAGS_PATH}:/opt/airflow/dags
      - ${AIRFLOW_LOGS_PATH}:/opt/airflow/logs
      - ${AIRFLOW_PLUGINS_PATH}:/opt/airflow/plugins
    ports:
      - "${AIRFLOW_PORT}:8080"
    command: >
      bash -c "
        airflow db upgrade &&
        airflow webserver --port 8080
      "
    networks:
      - shared-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Airflow Scheduler
  airflow-scheduler:
    image: apache/airflow:2.8.1
    container_name: airflow-scheduler-container
    restart: always
    depends_on:
      postgres_internal:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_INTERNAL_USER}:${POSTGRES_INTERNAL_PASSWORD}@postgres_internal/${POSTGRES_INTERNAL_DB}
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
    volumes:
      - ${AIRFLOW_DATA_PATH}:/opt/airflow
      - ${AIRFLOW_DAGS_PATH}:/opt/airflow/dags
      - ${AIRFLOW_LOGS_PATH}:/opt/airflow/logs
      - ${AIRFLOW_PLUGINS_PATH}:/opt/airflow/plugins
    command: airflow scheduler
    networks:
      - shared-network

  # =================================================================
  # DBT
  # =================================================================

  # Python Container for DBT Development
  python:
    image: python:3.12-slim
    container_name: python-dbt-container
    restart: unless-stopped
    volumes:
      - ${DBT_WORKSPACE_PATH}:/dbt-workspace
      - ./requirements-dbt.txt:/tmp/requirements-dbt.txt
      - ${DBT_PROJECTS_PATH}:/dbt-workspace/dbt-projects
    working_dir: /dbt-workspace
    command: >
      bash -c "
        pip install --upgrade pip &&
        pip install -r /tmp/requirements-dbt.txt &&
        echo 'Python and DBT environment is ready!' &&
        echo 'You can access it with: docker exec -it python-dbt-container bash' &&
        tail -f /dev/null
      "
    networks:
      - shared-network

  # =================================================================
  # SUPERSET
  # =================================================================

  # Apache Superset Database Initialization
  superset-init:
    image: apache/superset:6.0.0-dev
    container_name: superset-init-container
    depends_on:
      postgres_internal:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      SUPERSET_SECRET_KEY: ${SUPERSET_SECRET_KEY}
      SQLALCHEMY_DATABASE_URI: postgresql+psycopg2://${POSTGRES_INTERNAL_USER}:${POSTGRES_INTERNAL_PASSWORD}@postgres_internal:5432/${SUPERSET_DB}
      SUPERSET_CONFIG_PATH: /app/pythonpath/superset_config.py
      REDIS_HOST: redis
      REDIS_PORT: 6379
    user: "root"
    volumes:
      - ./superset-config:/app/pythonpath
    command: >
      bash -c "
        sleep 15 &&
        echo '=== Installing Snowflake connector ===' &&
        pip install --no-cache-dir snowflake-sqlalchemy==1.8.2 snowflake-connector-python==4.2.0 &&
        echo '=== Starting Superset Initialization ===' &&
        echo 'Database URI: postgresql+psycopg2://${POSTGRES_INTERNAL_USER}:*****@postgres_internal:5432/${SUPERSET_DB}' &&
        superset db upgrade &&
        superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@superset.com --password admin &&
        superset init &&
        echo '=== Superset Initialization Complete ==='
      "
    networks:
      - shared-network

  # Apache Superset Webserver
  superset:
    image: apache/superset:6.0.0-dev
    container_name: superset-container
    restart: always
    depends_on:
      postgres_internal:
        condition: service_healthy
      redis:
        condition: service_healthy
      superset-init:
        condition: service_completed_successfully
    environment:
      SUPERSET_SECRET_KEY: ${SUPERSET_SECRET_KEY}
      SQLALCHEMY_DATABASE_URI: postgresql+psycopg2://${POSTGRES_INTERNAL_USER}:${POSTGRES_INTERNAL_PASSWORD}@postgres_internal:5432/${SUPERSET_DB}
      SUPERSET_CONFIG_PATH: /app/pythonpath/superset_config.py
      REDIS_HOST: redis
      REDIS_PORT: 6379
    user: "root"
    volumes:
      - ${SUPERSET_DATA_PATH}:/app/superset_home
      - ./superset-config:/app/pythonpath
    ports:
      - "${SUPERSET_PORT}:8088"
    command: >
      bash -c "
        echo '=== Installing Snowflake connector ===' &&
        pip install --no-cache-dir snowflake-sqlalchemy==1.8.2 snowflake-connector-python==4.2.0 &&
        echo '=== Starting Superset Server ===' &&
        gunicorn --bind '0.0.0.0:8088' --workers 4 --timeout 120 --limit-request-line 0 --limit-request-field_size 0 'superset.app:create_app()'
      "
    networks:
      - shared-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8088/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =================================================================
  # AIRBYTE
  # =================================================================

  # Airbyte Bootloader (runs once)
  airbyte-bootloader:
    image: airbyte/bootloader:${AIRBYTE_VERSION}
    container_name: airbyte-bootloader
    depends_on:
      airbyte-postgres:
        condition: service_healthy
    environment:
      AIRBYTE_VERSION: ${AIRBYTE_VERSION}
      DATABASE_URL: ${DATABASE_URL}
      DATABASE_USER: ${POSTGRES_AIRBYTE_USER}
      DATABASE_PASSWORD: ${POSTGRES_AIRBYTE_PASSWORD}
      DATABASE_DB: ${POSTGRES_AIRBYTE_DB}
      CONFIG_ROOT: /configs
      WORKSPACE_ROOT: /workspace
      LOG_LEVEL: INFO
    volumes:
      - ${AIRBYTE_CONFIG_PATH}:/configs
      - ${AIRBYTE_WORKSPACE_PATH}:/workspace
    networks:
      - shared-network

  # Airbyte Temporal
  airbyte-temporal:
    image: airbyte/temporal:${AIRBYTE_VERSION}
    container_name: airbyte-temporal
    restart: unless-stopped
    environment:
      DB: postgresql
      DB_PORT: 5432
      POSTGRES_USER: ${POSTGRES_AIRBYTE_USER}
      POSTGRES_PWD: ${POSTGRES_AIRBYTE_PASSWORD}
      POSTGRES_SEEDS: airbyte-postgres
      LOG_LEVEL: INFO
    depends_on:
      airbyte-postgres:
        condition: service_healthy
      airbyte-bootloader:
        condition: service_completed_successfully
    networks:
      - shared-network

  # Airbyte Server (API)
  airbyte-server:
    image: airbyte/server:${AIRBYTE_VERSION}
    container_name: airbyte-server
    restart: unless-stopped
    depends_on:
      airbyte-bootloader:
        condition: service_completed_successfully
      airbyte-temporal:
        condition: service_started
    environment:
      AIRBYTE_VERSION: ${AIRBYTE_VERSION}
      DATABASE_URL: ${DATABASE_URL}
      DATABASE_USER: ${POSTGRES_AIRBYTE_USER}
      DATABASE_PASSWORD: ${POSTGRES_AIRBYTE_PASSWORD}
      DATABASE_DB: ${POSTGRES_AIRBYTE_DB}
      CONFIG_ROOT: /configs
      WORKSPACE_ROOT: /workspace
      TEMPORAL_HOST: airbyte-temporal:7233
      TRACKING_STRATEGY: logging
      WEBAPP_URL: ${WEBAPP_URL}
      WORKER_ENVIRONMENT: docker
      LOG_LEVEL: INFO
      AUTO_DETECT_SCHEMA: "true"
      MICRONAUT_ENVIRONMENTS: control-plane
      CONFIGS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION: 0.35.15.001
      JOBS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION: 0.29.15.001
      RUN_DATABASE_MIGRATION_ON_STARTUP: "true"
    ports:
      - "${INTERNAL_API_PORT}:8001"
    volumes:
      - ${AIRBYTE_CONFIG_PATH}:/configs
      - ${AIRBYTE_WORKSPACE_PATH}:/workspace
    networks:
      - shared-network

  # Airbyte Webapp (UI)
  airbyte-webapp:
    image: airbyte/webapp:${AIRBYTE_VERSION}
    container_name: airbyte-webapp
    restart: unless-stopped
    depends_on:
      - airbyte-server
    ports:
      - "${AIRBYTE_PORT}:80"
    environment:
      AIRBYTE_ROLE: webapp
      AIRBYTE_VERSION: ${AIRBYTE_VERSION}
      API_URL: /api/v1/
      INTERNAL_API_HOST: airbyte-server:8001
      CONNECTOR_BUILDER_API_HOST: airbyte-server:80
      CONNECTOR_BUILDER_API_URL: /connector-builder-api
      KEYCLOAK_INTERNAL_HOST: localhost
      TRACKING_STRATEGY: logging
    networks:
      - shared-network

  # Airbyte Worker
  airbyte-worker:
    image: airbyte/worker:${AIRBYTE_VERSION}
    container_name: airbyte-worker
    restart: unless-stopped
    depends_on:
      airbyte-bootloader:
        condition: service_completed_successfully
      airbyte-temporal:
        condition: service_started
    environment:
      AIRBYTE_VERSION: ${AIRBYTE_VERSION}
      DATABASE_URL: ${DATABASE_URL}
      DATABASE_USER: ${POSTGRES_AIRBYTE_USER}
      DATABASE_PASSWORD: ${POSTGRES_AIRBYTE_PASSWORD}
      DATABASE_DB: ${POSTGRES_AIRBYTE_DB}
      CONFIG_ROOT: /configs
      WORKSPACE_ROOT: /workspace
      LOCAL_ROOT: /tmp/airbyte_local
      TEMPORAL_HOST: airbyte-temporal:7233
      TRACKING_STRATEGY: logging
      WORKER_ENVIRONMENT: docker
      LOG_LEVEL: INFO
      INTERNAL_API_HOST: airbyte-server:8001
      AUTO_DETECT_SCHEMA: "true"
      MAX_SYNC_WORKERS: 5
      MAX_SPEC_WORKERS: 5
      MAX_CHECK_WORKERS: 5
      MAX_DISCOVER_WORKERS: 5
      CONFIGS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION: 0.35.15.001
      JOBS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION: 0.29.15.001
      SECRET_PERSISTENCE: TESTING_CONFIG_DB_TABLE
      MICRONAUT_ENVIRONMENTS: control-plane
    volumes:
      - ${AIRBYTE_CONFIG_PATH}:/configs
      - ${AIRBYTE_WORKSPACE_PATH}:/workspace
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - shared-network

  # Airbyte Cron
  airbyte-cron:
    image: airbyte/cron:${AIRBYTE_VERSION}
    container_name: airbyte-cron
    restart: unless-stopped
    depends_on:
      airbyte-bootloader:
        condition: service_completed_successfully
    environment:
      AIRBYTE_VERSION: ${AIRBYTE_VERSION}
      DATABASE_URL: ${DATABASE_URL}
      DATABASE_USER: ${POSTGRES_AIRBYTE_USER}
      DATABASE_PASSWORD: ${POSTGRES_AIRBYTE_PASSWORD}
      DATABASE_DB: ${POSTGRES_AIRBYTE_DB}
      CONFIG_ROOT: /configs
      WORKSPACE_ROOT: /workspace
      TEMPORAL_HOST: airbyte-temporal:7233
      TRACKING_STRATEGY: logging
      WORKER_ENVIRONMENT: docker
      LOG_LEVEL: INFO
      MICRONAUT_ENVIRONMENTS: control-plane
    volumes:
      - ${AIRBYTE_CONFIG_PATH}:/configs
      - ${AIRBYTE_WORKSPACE_PATH}:/workspace
    networks:
      - shared-network

# =================================================================
# NETWORK
# =================================================================

networks:
  shared-network:
    driver: bridge